{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a818b1b6-2620-474c-a708-4658d73d5610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import jax\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a3de8-6ce0-4e55-a9eb-0de428ac5359",
   "metadata": {},
   "source": [
    "# Trying To load T15 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41706659-de9f-4b1e-a266-18593598b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "ls = []\n",
    "parent_folder = \"/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\"\n",
    "if not os.path.exists(parent_folder):\n",
    "    print(\"Path not found!\")\n",
    "else:\n",
    "    for root, dirs, files in os.walk(parent_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".hdf5\"):\n",
    "                file_path = os.path.join(root,file)\n",
    "                ls.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdbbe75-30cf-46f3-924a-75eb7abfbf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.11/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.13/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.13/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.13/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.18/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.18/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.18/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.20/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.20/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.20/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.25/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.25/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.25/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.27/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.27/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.27/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.01/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.01/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.01/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.03/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.03/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.03/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.24/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.24/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.24/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.29/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.29/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.29/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.01/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.01/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.01/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.06/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.06/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.06/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.08/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.08/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.08/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.13/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.13/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.13/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.15/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.15/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.15/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.20/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.20/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.20/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.22/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.22/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.22/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.03/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.03/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.03/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.04/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.04/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.04/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.17/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.17/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.17/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.19/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.19/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.19/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.26/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.26/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.26/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.03/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.03/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.03/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.08/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.08/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.08/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.10/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.10/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.10/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.17/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.17/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.17/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.29/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.29/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.29/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.02.25/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.02.25/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.02.25/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.03/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.08/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.08/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.08/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.15/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.15/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.15/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.17/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.17/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.17/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.25/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.28/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.05.10/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.05.10/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.05.10/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.06.14/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.06.14/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.06.14/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.19/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.19/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.19/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.21/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.21/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.21/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.28/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.28/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.28/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.10/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.10/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.10/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.14/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.14/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.14/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.16/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.16/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.16/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.30/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.30/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.30/data_val.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.04.13/data_test.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.04.13/data_train.hdf5',\n",
       " '/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.04.13/data_val.hdf5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22696566-5eac-4841-8cad-751f796fde32",
   "metadata": {},
   "source": [
    "### Lets check whats within these hdf5 files...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b125bc-53c2-4e11-bd72-0d6fee52341d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in file: ['trial_0000', 'trial_0001', 'trial_0002', 'trial_0003', 'trial_0004', 'trial_0005', 'trial_0006', 'trial_0007', 'trial_0008', 'trial_0009', 'trial_0010', 'trial_0011', 'trial_0012', 'trial_0013', 'trial_0014', 'trial_0015', 'trial_0016', 'trial_0017', 'trial_0018', 'trial_0019', 'trial_0020', 'trial_0021', 'trial_0022', 'trial_0023', 'trial_0024', 'trial_0025', 'trial_0026', 'trial_0027', 'trial_0028', 'trial_0029', 'trial_0030', 'trial_0031', 'trial_0032', 'trial_0033', 'trial_0034', 'trial_0035', 'trial_0036', 'trial_0037', 'trial_0038', 'trial_0039', 'trial_0040', 'trial_0041', 'trial_0042', 'trial_0043', 'trial_0044', 'trial_0045', 'trial_0046', 'trial_0047', 'trial_0048', 'trial_0049', 'trial_0050', 'trial_0051', 'trial_0052', 'trial_0053', 'trial_0054', 'trial_0055', 'trial_0056', 'trial_0057', 'trial_0058', 'trial_0059', 'trial_0060', 'trial_0061', 'trial_0062', 'trial_0063', 'trial_0064', 'trial_0065', 'trial_0066', 'trial_0067', 'trial_0068', 'trial_0069', 'trial_0070', 'trial_0071', 'trial_0072', 'trial_0073', 'trial_0074', 'trial_0075', 'trial_0076', 'trial_0077', 'trial_0078', 'trial_0079', 'trial_0080', 'trial_0081', 'trial_0082', 'trial_0083', 'trial_0084', 'trial_0085', 'trial_0086', 'trial_0087', 'trial_0088', 'trial_0089', 'trial_0090', 'trial_0091', 'trial_0092', 'trial_0093', 'trial_0094', 'trial_0095', 'trial_0096', 'trial_0097', 'trial_0098', 'trial_0099', 'trial_0100', 'trial_0101', 'trial_0102', 'trial_0103', 'trial_0104', 'trial_0105', 'trial_0106', 'trial_0107', 'trial_0108', 'trial_0109', 'trial_0110', 'trial_0111', 'trial_0112', 'trial_0113', 'trial_0114', 'trial_0115', 'trial_0116', 'trial_0117', 'trial_0118', 'trial_0119', 'trial_0120', 'trial_0121', 'trial_0122', 'trial_0123', 'trial_0124', 'trial_0125', 'trial_0126', 'trial_0127', 'trial_0128', 'trial_0129', 'trial_0130', 'trial_0131', 'trial_0132', 'trial_0133', 'trial_0134', 'trial_0135', 'trial_0136', 'trial_0137', 'trial_0138', 'trial_0139', 'trial_0140', 'trial_0141', 'trial_0142', 'trial_0143', 'trial_0144', 'trial_0145', 'trial_0146', 'trial_0147', 'trial_0148', 'trial_0149', 'trial_0150', 'trial_0151', 'trial_0152', 'trial_0153', 'trial_0154', 'trial_0155', 'trial_0156', 'trial_0157', 'trial_0158', 'trial_0159', 'trial_0160', 'trial_0161', 'trial_0162', 'trial_0163', 'trial_0164', 'trial_0165', 'trial_0166', 'trial_0167', 'trial_0168', 'trial_0169', 'trial_0170', 'trial_0171', 'trial_0172', 'trial_0173', 'trial_0174', 'trial_0175', 'trial_0176', 'trial_0177', 'trial_0178', 'trial_0179', 'trial_0180', 'trial_0181', 'trial_0182', 'trial_0183', 'trial_0184', 'trial_0185', 'trial_0186', 'trial_0187', 'trial_0188', 'trial_0189', 'trial_0190', 'trial_0191', 'trial_0192', 'trial_0193', 'trial_0194', 'trial_0195', 'trial_0196', 'trial_0197', 'trial_0198', 'trial_0199', 'trial_0200', 'trial_0201', 'trial_0202', 'trial_0203', 'trial_0204', 'trial_0205', 'trial_0206', 'trial_0207', 'trial_0208', 'trial_0209', 'trial_0210', 'trial_0211', 'trial_0212', 'trial_0213', 'trial_0214', 'trial_0215', 'trial_0216', 'trial_0217', 'trial_0218', 'trial_0219', 'trial_0220', 'trial_0221', 'trial_0222', 'trial_0223', 'trial_0224', 'trial_0225', 'trial_0226', 'trial_0227', 'trial_0228', 'trial_0229', 'trial_0230', 'trial_0231', 'trial_0232', 'trial_0233', 'trial_0234', 'trial_0235', 'trial_0236', 'trial_0237', 'trial_0238', 'trial_0239', 'trial_0240', 'trial_0241', 'trial_0242', 'trial_0243', 'trial_0244', 'trial_0245', 'trial_0246', 'trial_0247', 'trial_0248', 'trial_0249', 'trial_0250', 'trial_0251', 'trial_0252', 'trial_0253', 'trial_0254', 'trial_0255', 'trial_0256', 'trial_0257', 'trial_0258', 'trial_0259', 'trial_0260', 'trial_0261', 'trial_0262', 'trial_0263', 'trial_0264', 'trial_0265', 'trial_0266', 'trial_0267', 'trial_0268', 'trial_0269', 'trial_0270', 'trial_0271', 'trial_0272', 'trial_0273', 'trial_0274', 'trial_0275', 'trial_0276', 'trial_0277', 'trial_0278', 'trial_0279', 'trial_0280', 'trial_0281', 'trial_0282', 'trial_0283', 'trial_0284', 'trial_0285', 'trial_0286', 'trial_0287']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "sample_file = ls[0]\n",
    "\n",
    "with h5py.File(sample_file, 'r') as f:\n",
    "    print(f\"Keys in file: {list(f.keys())}\")\n",
    "    \n",
    "    # Let's look at the shape of the data inside a key\n",
    "    for key in f.keys():\n",
    "        item = f[key]\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            print(f\"Key: {key} | Shape: {item.shape} | Type: {item.dtype}\")\n",
    "        else:\n",
    "            # print(f\"Key: {key} is a Group (folder)\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e5abd3-c6e9-46eb-bec5-aba6593efb99",
   "metadata": {},
   "source": [
    "### Shows that the HDF5 files are hierarchical i.e. Instead of one big block of data, your file is organized into \"Groups\" (which act like folders), where each group represents a single \"Trial\"\n",
    "\n",
    "##### > File Level: Contains ~288 folders (`trial_0000`, etc.).\n",
    "##### > Trial Level: Inside each `trial_XXXX` folder, you will find the actual Datasets (the neural arrays, the target text, etc.).\n",
    "\n",
    "### Let us look into a single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7150a77e-ac54-4f72-987f-930c88aeeda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting inside 'trial_0000' ---\n",
      "Keys: ['input_features', 'seq_class_ids', 'transcription']\n",
      "  [DATASET] Name: input_features       | Shape: (321, 512) | Type: float32\n",
      "  [DATASET] Name: seq_class_ids        | Shape: (500,) | Type: int32\n",
      "  [DATASET] Name: transcription        | Shape: (500,) | Type: int32\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "sample_file = ls[0]\n",
    "\n",
    "with h5py.File(sample_file, 'r') as f:\n",
    "    trial_group = f['trial_0000']\n",
    "    \n",
    "    print(f\"--- Inspecting inside 'trial_0000' ---\")\n",
    "    print(f\"Keys: {list(trial_group.keys())}\")\n",
    "    \n",
    "    # Loop through the items in this trial to see their shapes\n",
    "    for key in trial_group.keys():\n",
    "        data_item = trial_group[key]\n",
    "        \n",
    "        # Check if it's actual data (Dataset) or another folder\n",
    "        if isinstance(data_item, h5py.Dataset):\n",
    "            # We want to see the shape (e.g., [Time, Channels]) and type\n",
    "            print(f\"  [DATASET] Name: {key:<20} | Shape: {data_item.shape} | Type: {data_item.dtype}\")\n",
    "            \n",
    "            # If it's a small text label, let's print it to see what it says\n",
    "            if data_item.size < 10 and (data_item.dtype.kind in 'SUa'): # String/Unicode types\n",
    "                print(f\"            Value: {data_item[()]}\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"  [GROUP]   Name: {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20b7b6-1b6e-4d62-a971-504f0e982179",
   "metadata": {},
   "source": [
    "## The Challenge: \"Trials inside Files\"\n",
    "### You cannot just pass the list of file paths to the generic PyTorch loader because one file contains multiple samples (trials). If you have 100 files and each has 200 trials, you actually have 20,000 samples. To tackle this we create a `Global Index Map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da98077f-4930-4fb1-8a35-db8619f23241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing complete!\n",
      "Total files: 127\n",
      "Total individual trials (samples): 10948\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "samples_index = []\n",
    "\n",
    "for file_path in ls:\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # We just read the keys (trial names), we don't load the heavy data\n",
    "            trial_names = list(f.keys())\n",
    "            for t_name in trial_names:\n",
    "                samples_index.append((file_path, t_name))\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping broken file: {file_path}\")\n",
    "\n",
    "print(f\"Indexing complete!\")\n",
    "print(f\"Total files: {len(ls)}\")\n",
    "print(f\"Total individual trials (samples): {len(samples_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d1c92-29a0-4da5-a98d-953355eafdbb",
   "metadata": {},
   "source": [
    "### We load the given data into 3 different dataframes, which then we use later on as our reference dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3415571-390d-4a45-b024-e3c0469b2c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 127 files using FILENAME logic...\n",
      "\n",
      "--- FINAL SPLIT REPORT ---\n",
      "split       has_labels\n",
      "test        False         1450\n",
      "train       True          8072\n",
      "validation  True          1426\n",
      "Name: n_trials, dtype: int64\n",
      "\n",
      "[SUCCESS] All Validation files have labels! You can calculate accuracy immediately.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ls = [ ... your list of file paths ... ]\n",
    "\n",
    "manifest = []\n",
    "\n",
    "print(f\"Scanning {len(ls)} files using FILENAME logic...\")\n",
    "\n",
    "for file_path in ls:\n",
    "    try:\n",
    "        # Extract filename and folder info\n",
    "        file_name = os.path.basename(file_path)\n",
    "        path_parts = file_path.replace('\\\\', '/').split('/')\n",
    "        session_date = next((p for p in path_parts if p.startswith('t15.')), \"Unknown\")\n",
    "        \n",
    "        # 1. DETERMINE TYPE BY FILENAME\n",
    "        if \"train\" in file_name:\n",
    "            split_type = \"train\"\n",
    "        elif \"val\" in file_name:\n",
    "            split_type = \"validation\"\n",
    "        elif \"test\" in file_name:\n",
    "            split_type = \"test\"\n",
    "        else:\n",
    "            split_type = \"unknown\"\n",
    "\n",
    "        # 2. VERIFY CONTENTS (Do labels exist?)\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            if len(f.keys()) == 0:\n",
    "                continue\n",
    "                \n",
    "            first_trial = list(f.keys())[0]\n",
    "            group = f[first_trial]\n",
    "            \n",
    "            has_labels = 'transcription' in group\n",
    "            n_trials = len(f.keys())\n",
    "            \n",
    "            manifest.append({\n",
    "                'file_path': file_path,\n",
    "                'session_date': session_date,\n",
    "                'filename': file_name,\n",
    "                'split': split_type,      # 'train', 'val', 'test'\n",
    "                'has_labels': has_labels, # True/False\n",
    "                'n_trials': n_trials\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# --- SUMMARY REPORT ---\n",
    "df = pd.DataFrame(manifest)\n",
    "df.to_csv(\"t15_split_manifest.csv\", index=False)\n",
    "\n",
    "print(\"\\n--- FINAL SPLIT REPORT ---\")\n",
    "print(df.groupby(['split', 'has_labels'])['n_trials'].sum())\n",
    "\n",
    "# CRITICAL CHECK: Does validation data have labels?\n",
    "val_labels = df[df['split'] == 'validation']['has_labels'].all()\n",
    "if val_labels:\n",
    "    print(\"\\n[SUCCESS] All Validation files have labels! You can calculate accuracy immediately.\")\n",
    "else:\n",
    "    print(\"\\n[WARNING] Some Validation files are missing labels. Check the CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f180bccf-a14b-4189-b7a1-4108169f2e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DATASET SPLIT REPORT ---\n",
      "TRAIN Set : 45 files\n",
      "VAL Set   : 41 files\n",
      "TEST Set  : 41 files\n",
      "------------------------------\n",
      "TOTAL     : 127 files\n",
      "\n",
      "[OK] Integrity Check: All Train and Validation files have labels.\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the Master Manifest we created in the previous step\n",
    "manifest_path = \"t15_split_manifest.csv\"\n",
    "\n",
    "if not os.path.exists(manifest_path):\n",
    "    print(f\"Error: '{manifest_path}' not found. Please run the Classification Script first.\")\n",
    "else:\n",
    "    # Read the full list\n",
    "    full_df = pd.read_csv(manifest_path)\n",
    "    \n",
    "    # 2. Filter into 3 DataFrames\n",
    "    # We create copies (.copy()) so we can modify them later without warnings\n",
    "    train_df = full_df[full_df['split'] == 'train'].copy()\n",
    "    val_df   = full_df[full_df['split'] == 'validation'].copy()\n",
    "    test_df  = full_df[full_df['split'] == 'test'].copy()\n",
    "\n",
    "    # 3. Verify the Counts\n",
    "    print(\"--- DATASET SPLIT REPORT ---\")\n",
    "    print(f\"TRAIN Set : {len(train_df)} files\")\n",
    "    print(f\"VAL Set   : {len(val_df)} files\")\n",
    "    print(f\"TEST Set  : {len(test_df)} files\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"TOTAL     : {len(full_df)} files\")\n",
    "\n",
    "    # 4. Quick Sanity Check\n",
    "    # Ensure Train/Val actually have labels (should be True)\n",
    "    train_has_labels = train_df['has_labels'].all()\n",
    "    val_has_labels = val_df['has_labels'].all()\n",
    "    \n",
    "    if train_has_labels and val_has_labels:\n",
    "        print(\"\\n[OK] Integrity Check: All Train and Validation files have labels.\")\n",
    "    else:\n",
    "        print(\"\\n[WARNING] Some Train/Val files are missing labels! Check your manifest.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae5e831-4d01-425e-b5c9-ea349e43e02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>session_date</th>\n",
       "      <th>filename</th>\n",
       "      <th>split</th>\n",
       "      <th>has_labels</th>\n",
       "      <th>n_trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.08.11</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.08.13</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.08.18</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.08.20</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.08.25</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.08.27</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.09.01</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.09.03</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.09.24</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.09.29</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.10.01</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.10.06</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.10.08</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.10.13</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.10.15</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.10.20</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.10.22</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.11.03</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.11.04</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.11.17</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.11.19</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.11.26</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.12.03</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.12.08</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.12.10</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.12.17</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2023.12.29</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.02.25</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.03.03</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.03.08</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.03.15</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.03.17</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.04.25</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.04.28</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.05.10</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.06.14</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.07.19</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.07.21</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2024.07.28</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2025.01.10</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2025.01.12</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2025.03.14</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2025.03.16</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2025.03.30</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>/mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...</td>\n",
       "      <td>t15.2025.04.13</td>\n",
       "      <td>data_train.hdf5</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file_path    session_date  \\\n",
       "0    /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.08.11   \n",
       "2    /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.08.13   \n",
       "5    /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.08.18   \n",
       "8    /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.08.20   \n",
       "11   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.08.25   \n",
       "14   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.08.27   \n",
       "17   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.09.01   \n",
       "20   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.09.03   \n",
       "23   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.09.24   \n",
       "26   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.09.29   \n",
       "29   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.10.01   \n",
       "32   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.10.06   \n",
       "35   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.10.08   \n",
       "38   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.10.13   \n",
       "41   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.10.15   \n",
       "44   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.10.20   \n",
       "47   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.10.22   \n",
       "50   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.11.03   \n",
       "53   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.11.04   \n",
       "56   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.11.17   \n",
       "59   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.11.19   \n",
       "62   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.11.26   \n",
       "65   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.12.03   \n",
       "68   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.12.08   \n",
       "71   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.12.10   \n",
       "74   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.12.17   \n",
       "77   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2023.12.29   \n",
       "80   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.02.25   \n",
       "82   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.03.03   \n",
       "84   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.03.08   \n",
       "87   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.03.15   \n",
       "90   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.03.17   \n",
       "92   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.04.25   \n",
       "93   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.04.28   \n",
       "95   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.05.10   \n",
       "98   /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.06.14   \n",
       "101  /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.07.19   \n",
       "104  /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.07.21   \n",
       "107  /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2024.07.28   \n",
       "110  /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2025.01.10   \n",
       "113  /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2025.01.12   \n",
       "116  /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2025.03.14   \n",
       "119  /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2025.03.16   \n",
       "122  /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2025.03.30   \n",
       "125  /mnt/c/Users/Siddh/Datasets/brain-to-text-25/t...  t15.2025.04.13   \n",
       "\n",
       "            filename  split  has_labels  n_trials  \n",
       "0    data_train.hdf5  train        True       288  \n",
       "2    data_train.hdf5  train        True       348  \n",
       "5    data_train.hdf5  train        True       197  \n",
       "8    data_train.hdf5  train        True       278  \n",
       "11   data_train.hdf5  train        True        88  \n",
       "14   data_train.hdf5  train        True       150  \n",
       "17   data_train.hdf5  train        True       297  \n",
       "20   data_train.hdf5  train        True       322  \n",
       "23   data_train.hdf5  train        True       245  \n",
       "26   data_train.hdf5  train        True       153  \n",
       "29   data_train.hdf5  train        True       218  \n",
       "32   data_train.hdf5  train        True       174  \n",
       "35   data_train.hdf5  train        True       284  \n",
       "38   data_train.hdf5  train        True       155  \n",
       "41   data_train.hdf5  train        True       239  \n",
       "44   data_train.hdf5  train        True        98  \n",
       "47   data_train.hdf5  train        True       134  \n",
       "50   data_train.hdf5  train        True       149  \n",
       "53   data_train.hdf5  train        True        80  \n",
       "56   data_train.hdf5  train        True       100  \n",
       "59   data_train.hdf5  train        True        60  \n",
       "62   data_train.hdf5  train        True       198  \n",
       "65   data_train.hdf5  train        True       228  \n",
       "68   data_train.hdf5  train        True       198  \n",
       "71   data_train.hdf5  train        True       131  \n",
       "74   data_train.hdf5  train        True       135  \n",
       "77   data_train.hdf5  train        True       198  \n",
       "80   data_train.hdf5  train        True       193  \n",
       "82   data_train.hdf5  train        True       219  \n",
       "84   data_train.hdf5  train        True       163  \n",
       "87   data_train.hdf5  train        True       239  \n",
       "90   data_train.hdf5  train        True       246  \n",
       "92   data_train.hdf5  train        True       364  \n",
       "93   data_train.hdf5  train        True       150  \n",
       "95   data_train.hdf5  train        True       110  \n",
       "98   data_train.hdf5  train        True        90  \n",
       "101  data_train.hdf5  train        True       169  \n",
       "104  data_train.hdf5  train        True       160  \n",
       "107  data_train.hdf5  train        True       161  \n",
       "110  data_train.hdf5  train        True       106  \n",
       "113  data_train.hdf5  train        True       163  \n",
       "116  data_train.hdf5  train        True        59  \n",
       "119  data_train.hdf5  train        True       101  \n",
       "122  data_train.hdf5  train        True       165  \n",
       "125  data_train.hdf5  train        True        69  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce652497-fbbf-48ec-b6ce-b742f86f6d36",
   "metadata": {},
   "source": [
    "### Building a character vocabulary set, we'll use the train_df as reference to build it and identify every unique character in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180628cc-6fac-47c1-ac46-a6bcf4b54268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 45 training files to build the keyboard...\n",
      "\n",
      "--- KEYBOARD BUILT ---\n",
      "Found 62 unique characters.\n",
      "Total Model Output Size: 63 (including Blank)\n",
      "Characters:  !',-.;?ABCDEFGHIJKLMNOPQRSTUVWYZ[]abcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import json\n",
    "import os\n",
    "\n",
    "train_files = train_df['file_path'].to_list()\n",
    "\n",
    "print(f\"Scanning {len(train_files)} training files to build the keyboard...\")\n",
    "unique_chars = set()\n",
    "\n",
    "for file_path in train_files:\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            for key in f.keys():\n",
    "                group = f[key]\n",
    "                \n",
    "                # Check for the sentence text in attributes\n",
    "                if 'sentence_label' in group.attrs:\n",
    "                    sentence = group.attrs['sentence_label']\n",
    "                    \n",
    "                    # Convert bytes to string if needed\n",
    "                    if isinstance(sentence, bytes):\n",
    "                        sentence = sentence.decode('utf-8')\n",
    "                        \n",
    "                    # Add every character to our set\n",
    "                    for char in sentence:\n",
    "                        unique_chars.add(char)\n",
    "                        \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file: {e}\")\n",
    "# --- FORMATTING THE VOCAB ---\n",
    "# Sort the list so 'a' always comes before 'b'\n",
    "sorted_chars = sorted(list(unique_chars))\n",
    "\n",
    "# Create the map: Char -> Number\n",
    "# We start at 1 because 0 is usually reserved for the \"Blank\" token in CTC Loss\n",
    "char_to_int = {char: idx + 1 for idx, char in enumerate(sorted_chars)}\n",
    "int_to_char = {idx + 1: char for idx, char in enumerate(sorted_chars)}\n",
    "\n",
    "# Add the special CTC Blank Token\n",
    "char_to_int['<BLANK>'] = 0\n",
    "int_to_char[0] = '<BLANK>'\n",
    "\n",
    "# Save it!\n",
    "vocab_data = {\n",
    "    'char_to_int': char_to_int,\n",
    "    'int_to_char': int_to_char,\n",
    "    'n_classes': len(char_to_int) # This tells us how many output neurons we need\n",
    "}\n",
    "\n",
    "with open(\"t15_vocab.json\", \"w\") as f:\n",
    "    json.dump(vocab_data, f, indent=4)\n",
    "\n",
    "print(\"\\n--- KEYBOARD BUILT ---\")\n",
    "print(f\"Found {len(sorted_chars)} unique characters.\")\n",
    "print(f\"Total Model Output Size: {len(char_to_int)} (including Blank)\")\n",
    "print(f\"Characters: {''.join(sorted_chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f3ed54-cf18-4e75-9151-2007cb8248b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.cuda.device_count())\n",
    "# print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b454a77a-9008-4a66-a2dc-fdca098b4654",
   "metadata": {},
   "source": [
    "## Complete Preprocesing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce508166-c7d2-4ac8-b199-7d495caa0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class T15Preprocessor:\n",
    "#     def __init__(self, bin_size_ms=20, smooth_sigma_ms=80, threshold_rms=-4.5):\n",
    "#         self.bin_size_ms = bin_size_ms\n",
    "#         self.sigma = smooth_sigma_ms / bin_size_ms # Convert ms -> bins\n",
    "#         self.threshold = threshold_rms\n",
    "\n",
    "#     def __call__(self, raw_spikes):\n",
    "#         n_bins = raw_spikes.shape[0] // self.bin_size_ms\n",
    "#         binned = raw_spikes[:n_bins * self.bin_size_ms]\n",
    "#         binned = binned.reshape(n_bins, self.bin_size_ms, -1).sum(axis=1)\n",
    "#         mean = np.mean(binned, axis=0)\n",
    "#         std = np.std(binned, axis=0)\n",
    "#         std[std < 1e-6] = 1.0\n",
    "#         normalized = (binned - mean) / std\n",
    "#         normalized = np.clip(normalized, -10, 10)\n",
    "#         smoothed = gaussian_filter1d(normalized, sigma=self.sigma, axis=0)\n",
    "\n",
    "#         return smoothed.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bf89f08-117a-4d81-b2a4-469220ce6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f1167a4-6056-4dbd-bf42-e19fdea0e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T15Dataset(Dataset):\n",
    "    def __init__(self, df, vocab_path=\"t15_vocab.json\", smooth_sigma=4.0, clip_val=5.0, augment=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.smooth_sigma = smooth_sigma\n",
    "        self.clip_val = clip_val\n",
    "        self.augment = augment\n",
    "\n",
    "        #Load Vocabulary - \n",
    "        with open(vocab_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            self.char_to_int = data['char_to_int']\n",
    "            self.blank_token = 0 #CTC requires a blank token at index 0 ,i.e. for unknown characters\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    #Converts 'Hello' -> [8, 5, 12, 12, 15] based on vocab.\n",
    "    def text_to_int(self, text):\n",
    "        result = []\n",
    "        for char in text:\n",
    "            if char in self.char_to_int:\n",
    "                result.append(self.char_to_int[char])\n",
    "        return torch.LongTensor(result)\n",
    "\n",
    "    # ARTIFACT REMOVAL (Dead/Saturated Channel Mask), Identify channels that are completely silent(std ~ 0) or screaming(std > 50) BEFORE normalization\n",
    "    def preprocess_neural(self, neural_data):\n",
    "        ch_std = np.std(neural_data, axis=0)\n",
    "        dead_channels = ch_std < 0.01\n",
    "\n",
    "        #Z-SCORE NORMALIZATION i.e. Normalize time-series to Mean=0, Std=1\n",
    "        mean = np.mean(neural_data, axis=0)\n",
    "        std = ch_std\n",
    "        std[std == 0] = 1.0\n",
    "        normalized = (neural_data - mean) / std\n",
    "        \n",
    "        #Apply the mask: Force dead channels to exactly 0.0\n",
    "        normalized[:, dead_channels] = 0.0\n",
    "        #CLIP OUTLIERS\n",
    "        normalized = np.clip(normalized, -self.clip_val, self.clip_val)\n",
    "        \n",
    "        #TEMPORAL SMOOTHING - Convolve with Gaussian kernel to make signals RNN-friendly\n",
    "        smoothed = gaussian_filter1d(normalized, sigma=self.smooth_sigma, axis=0)\n",
    "        \n",
    "        return torch.from_numpy(smoothed).float()\n",
    "\n",
    "    #Data Augmentation (Training Only) - Adds Gaussian White Noise to make the model robust.    \n",
    "    def apply_augmentation(self, neural_tensor):\n",
    "        noise_level = 0.1\n",
    "        noise = torch.randn_like(neural_tensor) * noise_level\n",
    "        return neural_tensor + noise\\\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        file_path = row['file_path']\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            #Fix Binning \n",
    "            key = list(f.keys())[0]\n",
    "            group = f[key]\n",
    "\n",
    "            #Load & Preprocess Input\n",
    "            raw_neural = group['input_features'][:]\n",
    "            neural_tensor = self.preprocess_neural(raw_neural)\n",
    "\n",
    "            #Augmentation (If enabled) - We will be enabling it for training and disabling it for validation\n",
    "            if self.augment:\n",
    "                neural_tensor = self.apply_augmentation(neural_tensor)\n",
    "                \n",
    "            #Load Target (Labels)\n",
    "            if 'sentence_label' in group.attrs:\n",
    "                sentence = group.attrs['sentence_label']\n",
    "                if isinstance(sentence, bytes):\n",
    "                    sentence = sentence.decode('utf-8')\n",
    "                target_tensor = self.text_to_int(sentence)\n",
    "            else:\n",
    "                target_tensor = torch.from_numpy(group['transcription'][:]).long()\n",
    "            # Lengths for CTC Loss\n",
    "            input_len = neural_tensor.shape[0]\n",
    "            target_len = len(target_tensor)\n",
    "        return neural_tensor, target_tensor, input_len, target_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4bf35c-db43-4633-b510-d2469592484a",
   "metadata": {},
   "source": [
    "### Creating two instances of this class. One for training (with noise) and one for validation (pure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a99a8b57-9324-43a1-8b23-e8ebdbea471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 45\n",
      "Val Size:   41\n"
     ]
    }
   ],
   "source": [
    "# 1. Training Dataset (With Augmentation enabled)\n",
    "train_dataset = T15Dataset(\n",
    "    df=train_df, \n",
    "    vocab_path=\"t15_vocab.json\", \n",
    "    augment=True  # <--- Step 9: Enabled\n",
    ")\n",
    "\n",
    "# 2. Validation Dataset (Clean data only)\n",
    "val_dataset = T15Dataset(\n",
    "    df=val_df, \n",
    "    vocab_path=\"t15_vocab.json\", \n",
    "    augment=False # <--- Disabled\n",
    ")\n",
    "\n",
    "print(f\"Train Size: {len(train_dataset)}\")\n",
    "print(f\"Val Size:   {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd90d2a-20b6-4f86-b7d8-142adcb81717",
   "metadata": {},
   "source": [
    "### `ctc_collate_fn` returns 4 things, not just 2: It essentially just performing padding of the translational sequences\n",
    "\n",
    "1. `padded_neural`: The rectangular input data (for the GPU).\n",
    "\n",
    "2. `padded_targets`: The rectangular labels (for the GPU).\n",
    "\n",
    "3. `input_lens`: A list saying [200, 500, 1000] (The real lengths).\n",
    "\n",
    "4. `target_lens`: A list saying [2, 11, 35] (The real character counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f41dfe8-186b-4127-99db-95b8d022e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def ctc_collate_fn(batch):\n",
    "    neural_tensors, target_tensors, input_lens, target_lens = zip(*batch)\n",
    "    padded_neural = pad_sequence(neural_tensors, batch_first=True, padding_value=0.0)\n",
    "    padded_targets = pad_sequence(target_tensors, batch_first=True, padding_value=-1)\n",
    "    input_lens = torch.tensor(input_lens, dtype=torch.long)\n",
    "    target_lens = torch.tensor(target_lens, dtype=torch.long)\n",
    "    return padded_neural, padded_targets, input_lens, target_lens\n",
    "train_dataset = T15Dataset(train_df, vocab_path=\"t15_vocab.json\", augment=True)\n",
    "val_dataset   = T15Dataset(val_df, vocab_path=\"t15_vocab.json\", augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb0bbe88-3df3-4ee8-b462-a02b7e0796af",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,       # ALWAYS shuffle training data\n",
    "    collate_fn=ctc_collate_fn,\n",
    "    num_workers=2,      # Uses multi-core CPU to load files faster\n",
    "    pin_memory=True     # Speeds up transfer to GPU\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,      # Never shuffle validation (keep order consistent)\n",
    "    collate_fn=ctc_collate_fn,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "487ccdf3-193c-4160-af72-b8ea4689732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BATCH INSPECTION ---\n",
      "Input Shape (Batch, Max_Time, 512): torch.Size([45, 1350, 512])\n",
      "Target Shape (Batch, Max_Seq_Len):  torch.Size([45, 55])\n",
      "Sample Input Lengths: [921, 605, 586, 1259, 321]\n",
      "\n",
      "[OK] Padding detected (zeros found at end of sequence).\n"
     ]
    }
   ],
   "source": [
    "# Grab first batch\n",
    "inputs, targets, in_lens, out_lens = next(iter(train_loader))\n",
    "\n",
    "print(\"\\n--- BATCH INSPECTION ---\")\n",
    "print(f\"Input Shape (Batch, Max_Time, 512): {inputs.shape}\")\n",
    "print(f\"Target Shape (Batch, Max_Seq_Len):  {targets.shape}\")\n",
    "print(f\"Sample Input Lengths: {in_lens[:5].tolist()}\")\n",
    "\n",
    "# Check for padding (should see zeros at the end of the first sample if it's shorter than max)\n",
    "if inputs.shape[1] > in_lens[0]:\n",
    "    print(\"\\n[OK] Padding detected (zeros found at end of sequence).\")\n",
    "else:\n",
    "    print(\"\\n[NOTE] First sequence was the longest, or batch sizes match exactly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e7a7c-8ad9-49dd-840f-cd00ad2398a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (System GPU)",
   "language": "python",
   "name": "system-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
